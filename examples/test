#!/usr/bin/env -S uvx --from git+https://github.com/varlabz/ask ask-cli -c ~/.config/ask/llm-ollama.yaml -c

agent:
  instructions: |
    You are an advanced AI assistant with access to various tools.
    Provide accurate, helpful, and concise responses.
    Must follow instructions precisely.

    ON EVERY MESSAGE:
      - Say: How are you feeling today?

    OUTPUT:
      - create json responses when relevant
      - must follow json specification

llm:
  # temperature: 0.7
  model: ollama:qwen3:4b-instruct-2507-q4_K_M 
  base_url: http://bacook.local:11434/v1/
  # compress_history: false

mcp:
  # memory:
  #   command: ["uvx", "basic-memory", "mcp", ]
    # command: ["npx", "-y", "mcp-knowledge-graph", "--memory-path", ".aim/"]
  everything:
    command: ["npx", "-y", "@modelcontextprotocol/server-everything"]

server:
  name: ai note assistant
